{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c11da4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from pathlib import Path\n",
    "from typing import NamedTuple, Tuple\n",
    "import pandas as pd\n",
    "import boto3\n",
    "from rekognition_objects import RekognitionFace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4c6c52",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "039d1c5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df = get_valdf()\n",
    "images = get_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbdf1c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceAnalysis(NamedTuple):\n",
    "    path: str\n",
    "    age: Tuple[int, int]\n",
    "    gender: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bed6a31d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rekognition_client = boto3.client('rekognition')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74c895a",
   "metadata": {},
   "source": [
    "## Function for analyzing images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e25b1b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def aws_analyze_image(path: Path) -> FaceAnalysis:\n",
    "    short_path = '/'.join(str(path).split('/')[-2:])\n",
    "    try:\n",
    "        with open(path, 'rb') as image_data:\n",
    "            image = {'Bytes': image_data.read()}\n",
    "            response = rekognition_client.detect_faces(Image = image, Attributes = ['ALL'])\n",
    "            faces = [RekognitionFace(face) for face in response['FaceDetails']]\n",
    "            face = faces[0]\n",
    "            return FaceAnalysis(path=short_path, age=face.age_range, gender=face.gender)\n",
    "    except:\n",
    "        return FaceAnalysis(path=short_path, age=None, gender=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4af732",
   "metadata": {},
   "source": [
    "## Building the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2eebc942",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths, ages, genders = [], [], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bed6a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "1600\n",
      "1800\n",
      "2000\n",
      "2200\n",
      "2400\n",
      "2600\n",
      "2800\n",
      "3000\n",
      "3200\n",
      "3400\n",
      "3600\n",
      "3800\n",
      "4000\n",
      "4200\n",
      "4400\n",
      "4600\n",
      "4800\n",
      "5000\n",
      "5200\n",
      "5400\n",
      "5600\n",
      "5800\n",
      "6000\n",
      "6200\n",
      "6400\n",
      "6600\n",
      "6800\n",
      "7000\n",
      "7200\n",
      "7400\n",
      "7600\n",
      "7800\n",
      "8000\n",
      "8200\n",
      "8400\n",
      "8600\n",
      "8800\n",
      "9000\n",
      "9200\n",
      "9400\n",
      "9600\n",
      "9800\n",
      "10000\n",
      "10200\n",
      "10400\n",
      "10600\n",
      "10800\n"
     ]
    }
   ],
   "source": [
    "for idx, im in enumerate(images):\n",
    "    if idx % 200 == 0:\n",
    "        print(idx)\n",
    "    face = aws_analyze_image(im)\n",
    "    paths.append(face.path)\n",
    "    ages.append(face.age)\n",
    "    genders.append(face.gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "db186e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzed_df = pd.DataFrame({'path': paths, 'predicted_age': ages, 'predicted_gender': genders})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6116f729",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzed_df['predicted_age'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd608598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>predicted_age</th>\n",
       "      <th>predicted_gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>val/9733.jpg</td>\n",
       "      <td>(23, 37)</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>val/63.jpg</td>\n",
       "      <td>(4, 14)</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>val/6400.jpg</td>\n",
       "      <td>(25, 39)</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>val/823.jpg</td>\n",
       "      <td>(26, 40)</td>\n",
       "      <td>Male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>val/4217.jpg</td>\n",
       "      <td>(2, 8)</td>\n",
       "      <td>Female</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           path predicted_age predicted_gender\n",
       "0  val/9733.jpg      (23, 37)             Male\n",
       "1    val/63.jpg       (4, 14)           Female\n",
       "2  val/6400.jpg      (25, 39)           Female\n",
       "3   val/823.jpg      (26, 40)             Male\n",
       "4  val/4217.jpg        (2, 8)           Female"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzed_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31543942",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_df.merge(analyzed_df, left_on = 'file', right_on = 'path').to_csv('aws_val_merged.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e1d3d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
